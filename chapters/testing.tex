\chapter{Attività di Test}
\label{chap:testing}
In questo capitolo si procede a effettuare dei test di performance sul funzionamento del sistema appena introdotto. Per fare questo genere di test è stato utilizzato \emph{JMeter}: un tool per misurare le prestazioni di un sistema mediante dei test di carico. Durante questi test si confrontano le vecchie API con quelle implementate nel capitolo precedente.

\section{Configurazione di JMeter}
\emph{JMeter} è un progetto open source appartanente all'\emph{Apache Foundation}. La vera particolarità di questo software è quella di essere perfettamente configurabile per automatizzare le operazioni di test di carico su macchine remote. Nel nostro caso è stato utilizzato per testare le richieste, mediante le API, al database. Sono stati realizzati due progetti: il primo relativo alle vecchie API di Zerocoda, il secondo relativo alle nuove, oggetto di questo elaborato. E' stata simulata l'azione concorrenziale di più utenti (thread) che attraverso un dataset di valori pre inseriti andassero a richiamare le API. Per una corretta interpretazione dei risultati, la configurazione è rimasta la stessa tra i due progetti. È rimasto \textit{invariato il numero di thread}, l'intervallo (in secondi) in cui questi venivano chiamati, e il numero di loop (serie di operazione) eseguito da ogni thread. Le operazioni svolte da ciascun test mirano a simulare l'attività di un utente sul sistema, e in ordine sono:
\begin{enumerate}
    \item Ricerca delle strutture
    \item Ricerca del calendario di una struttura
    \item Ricerca degli slot di un calendario
    \item Prenotazione di un servizio
    \item Cancellazione della prenotazione appena effettuata
\end{enumerate}
I dati inseriti sono stati gestiti attraverso diversi dataset, che a ogni loop fornivano a ciascun thread il parametro da utilizzare nelle richieste. Per evitare errori si è fatto sì che i thread non prenotassero nello stesso momento lo stesso servizio. Questo, una volta prenotato, restituiva il codice di prenotazione, che veniva utilizzato dalla richiesta successiva per cancellare la prenotazione dell'utente.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Risultati Ottenuti}
Di seguito vengono illustrati i grafici realizzati con appositi plugin di JMeter. Si fa riferimento a due tipologie grafico:
\begin{itemize}
    \item \textbf{Response Time}: il tempo di risposta in millisecondi di ogni richiesta (asse delle ordinate) viene calcolato in funzione dell'orario in cui la richiesta è stata effettuata (sull'asse delle ascisse) 
    \item \textbf{Aggregate Graph}: per ogni richiesta (asse delle ascisse) viene presentata la media dei tempi di risposta in millisecondi (asse delle ordinate)
\end{itemize}

\subsection{Vecchie API}
\begin{figure}
    \centering
    \includegraphics[width=0.90\textwidth]{images/04_1_old_api_response_graph_legend.pdf}
    \caption{Response Graph - Old API}
    \label{fig:oldapi100t_response}
\end{figure}
Le API precedenti al refactoring sono messe molto alla prova già con un centinaio di utenti che operano sul sistema (Figura \ref{fig:oldapi100t_response}). Per le operazioni di lettura sul database vengono impiegati circa \emph{0,8 secondi}, mentre il tempo si alza per le operazioni di scrittura, dove una richiesta può impiegare fino a quasi \emph{5 secondi} per restituire una risposta.
%\begin{figure}[H]
%    \centering
%    \includegraphics[width=0.80\textwidth]{images/04_2_old_api_aggregate_graph_legend.pdf}
%    \caption{Aggregate Graph - Old API}
%    \label{fig:oldapi100t_aggregate}
%\end{figure}
Nella tabellla mostrata in Figura \ref{fig:oldapi100t_summary} viene mostrata le media (in millisecondi) dei tempi di risposta per ogni richiesta. Anche le richieste più semplici possono impiegare fino a \emph{1 secondo} per l'elaborazione, se il sistema viene messo sotto sforzo.
\begin{figure}[H]
    \begin{table}[H]
        \centering
        \begin{tabular}{ |p{3cm}||p{2cm}|p{2cm}|p{1cm}|p{1cm}|p{2cm}| }
            \hline
            Request & \# Samples & Average  & Min & Max &  Throughput\\
            \hline
            GET Facilities      & 10000    & 547   & 29 & 6625 & 9,65525      \\
            GET Calendar        & 10000    & 745   & 37 & 6546        & 9,65532      \\
            GET Slots        & 10000    & 642   & 31 & 4129        & 9,65546      \\
            GET Conf. Res.        & 10000    & 4205    & 72 & 9978        & 9,65418      \\
            GET Can. Res        & 10000    & 3773    & 96 & 9432        & 9,65309      \\
            TOTAL        & 50000    & 1983    & 29 & 9978        & 48,24383      \\
            \hline
        \end{tabular}
    \end{table}
    \caption{Sommario del Test - Vecchie API}
    \label{fig:oldapi100t_summary}
\end{figure}
Per questo test, così come per il successivo, si è testato uno scenario in cui 100 utenti (threads) eseguono in parallelo le chiamate mostrate, per un totale di 100 volte. I \emph{samples} rappresentano il numero di loop in cui è stata eseguita ciascuna richiesta. Si osservino i parametri ottenuti nel \emph{throughput}, e si tengano a mente per analizzare i corrispettivi valori nelle nuove API.

\subsection{Nuove API}
Le nuove API hanno dato un esito positivo sin dal loro tempo di esecuzione. I test sono stati eseguiti separatamente, in modo che l'accesso al database da parte di un backend non andasse a influire sulla richiesta di connessione da parte del backend rivale. Il test svolto con le nuove API ha avuto un \emph{tempo di esecuzione quasi 20 volte minore al precedente}. Un risultato straordinario, ma sostenuto da diverse ragioni. In Figura \ref{fig:newapi100t_response} viene presentato il grafico relativo ai tempi di risposta di ciascuna chiamata. I tempi in millisecondi, rispetto al grafico precedente, risultano parecchio ridotti. Anche le chiamate con i metodi POST o DELETE, che vanno ad effettuare delle operazioni sul database hanno comunque dei tempi minori rispetto a una qualsiasi GET che nelle vecchie API si limitasse a leggere dei valori sul database. Tutte le richieste nel complesso hanno presentato un miglioramento. Se nel primo grafico a seguito di un picco il sistema stabilizzava le risposte su quel tempo, ora a un picco segue un riabbassamento, e \emph{la gestione delle connessioni appare più controllata.} Il picco è limitato a un istante di tempo, e in seguito ad esso il sistema abbassa nuovamente i propri tempi di risposta.
\begin{figure}
    \centering
    \includegraphics[width=0.90\textwidth]{images/04_3_new_api_response_graph_legend.pdf}
    \caption{Response Graph - New API}
    \label{fig:newapi100t_response}
\end{figure}
\begin{figure}[H]
    \begin{table}[H]
        \centering
        \begin{tabular}{ |p{3cm}||p{2cm}|p{2cm}|p{1cm}|p{1cm}|p{2cm}| }
            \hline
            Request & \# Samples & Average  & Min & Max &  Throughput\\
            \hline
            GET Facilities      & 10000    & 89   & 4 & 7 & 100,43993      \\
            GET Calendar        & 10000    & 150   & 4 & 780        & 100,44699      \\
            GET Slots        & 10000    & 217   & 9 & 884        & 100.44295      \\
            POST Reser.        & 10000    & 245    & 12 & 1164        & 100,44598      \\
            DELETE Reserv.        & 10000    & 237    & 11 & 1012        & 100,45203      \\
            TOTAL        & 50000    & 188    & 4 & 1164        & 502,00299      \\
            \hline
        \end{tabular}
    \end{table}
    \caption{Sommario del Test - Vecchie API}
    \label{fig:oldapi100t_summary}
\end{figure}